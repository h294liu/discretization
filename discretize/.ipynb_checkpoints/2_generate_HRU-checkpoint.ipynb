{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate HRU at different complexity levels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import geospatial_functions.utils as ut\n",
    "import geospatial_functions.geospatial_analysis as ga\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common paths\n",
    "control_file = 'control_active.txt'\n",
    "root_path = ut.read_from_control(control_file, 'root_path')\n",
    "source_path = ut.read_from_control(control_file, 'source_path')\n",
    "domain_name = ut.read_from_control(control_file, 'domain_name')\n",
    "domain_path = os.path.join(root_path, domain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain data\n",
    "domain_gru_prj_shp = ut.specify_file_path(control_file, 'domain_gru_prj_shp')\n",
    "domain_gru_raster = ut.specify_file_path(control_file, 'domain_gru_raster')\n",
    "gruNo_field = ut.read_from_control(control_file, 'gruNo_field')\n",
    "gruNo_field_dtype = ut.read_from_control(control_file, 'gruNo_field_dtype')\n",
    "gruName_field = ut.read_from_control(control_file, 'gruName_field')\n",
    "domain_gru_corr_txt = ut.specify_file_path(control_file, 'domain_gru_corr_txt')\n",
    "\n",
    "domain_dem_raster = ut.specify_file_path(control_file, 'domain_dem_raster')  \n",
    "domain_slope_raster = ut.specify_file_path(control_file, 'domain_slope_raster')  \n",
    "domain_aspect_raster = ut.specify_file_path(control_file, 'domain_aspect_raster')\n",
    "domain_landcover_class_raster = ut.specify_file_path(control_file, 'domain_landcover_class_raster')\n",
    "domain_soil_raster = ut.specify_file_path(control_file, 'domain_soil_raster')\n",
    "domain_radiation_raster = ut.specify_file_path(control_file, 'domain_radiation_raster')\n",
    "\n",
    "refraster = ut.specify_refraster_path(control_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hru data\n",
    "hruNo_field = ut.read_from_control(control_file, 'hruNo_field')\n",
    "hruNo_field_dtype = ut.read_from_control(control_file,'hruNo_field_dtype') # used to save hruNo raster. \n",
    "hruName_field = ut.read_from_control(control_file,'hruName_field')         # field name of hru name, e.g., 10080012010101, 100800120102. \n",
    "    \n",
    "elev_class_field = ut.read_from_control(control_file,'elev_class_field')           # field name of the elevation class column in HRU. \n",
    "land_class_field = ut.read_from_control(control_file,'land_class_field')           # field name of the land class column in HRU. \n",
    "radiation_class_field = ut.read_from_control(control_file,'radiation_class_field') # field name of the radiation class column in HRU. \n",
    "hru_area_field =  = ut.read_from_control(control_file,'hru_area_field')            # field name of the HRU area.\n",
    "\n",
    "hru_thld_type = ut.read_from_control(control_file,'hru_thld_type')         # use a fraction or area value to eliminate small HRUs.\n",
    "hru_thld = float(ut.read_from_control(control_file, 'hru_thld'))           # if hru_thld_type = 'fraction', hru_thld = partial of the gru area.\n",
    "                                                                           ## if hru_thld_type = 'value', hru_thld = elimination area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basename for dem and radiation classification in a hru level.\n",
    "dem_class_basename = 'dem_class' # basename for DEM class files (eg, 0:low elevation. 1: high elevation).\n",
    "dem_value_basename = 'dem_value' # basename for DEM value files (eg, average DEM per class).\n",
    "\n",
    "rad_class_basename = 'rad_class' # basename for radiation class files (eg, 0:low. 1:high).\n",
    "rad_value_basename = 'rad_value' # basename for radiation value files (eg, average radiation per class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define HRU complexity levels ####\n",
    "level 0: GRU = HRU. <br>\n",
    "level 1: use only elevation bands in HRU generation.<br>\n",
    "level 2a: use elevation bands and landcover classes in HRU generation.<br>\n",
    "level 2b: use elevation bands and radiation classes in HRU generation.<br>\n",
    "level 3a: use elevation bands, radiation bands, landcover classes in HRU generation.<br>\n",
    "level 3b: nested. radiation bands are generated based on level 2a HRU.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_list = ['0','1','2a','2b','3a','3b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Discretize HRU ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 2b ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 51.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for level in level_list:\n",
    "\n",
    "    print('--- Complexity level %s ---' %(level))\n",
    "    \n",
    "    #  --- PART 1. define output files of discretization--- \n",
    "    hru_str = 'hru'+'_lev' + str(level)\n",
    "    hru_elmn_str = hru_str+'_elmn'     \n",
    "    \n",
    "    hru_raster = os.path.join(domain_path, hru_str+'.tif')            # original HRU\n",
    "    hru_vector = os.path.join(domain_path, hru_str+'.shp')\n",
    "    hru_raster_elmn = os.path.join(domain_path, hru_elmn_str+'.tif')  # simplified HRU\n",
    "    hru_vector_elmn = os.path.join(domain_path, hru_elmn_str+'.shp')    \n",
    "\n",
    "    dem_classif_trigger = 300 # Elvation difference value per GRU used to trigger elevation classification.\n",
    "    dem_bins = 'median' # Elevation classification method. 'median' means using the median value per GRU as the classification threhold.\n",
    "    dem_class_raster = os.path.join(domain_path, dem_class_basename+'_lev'+str(level)+'.tif')\n",
    "    dem_value_raster = os.path.join(domain_path, dem_value_basename+'_lev'+str(level)+'.tif')\n",
    "    \n",
    "    rad_classif_trigger = 50 #None # Radiation difference value per GRU used to trigger elevation classification.\n",
    "    rad_bins = 'median' # Radiation classification method. 'median' means using the median value per GRU as the classification threhold.\n",
    "    rad_class_raster = os.path.join(domain_path, rad_class_basename+'_lev'+str(level)+'.tif')\n",
    "    rad_value_raster = os.path.join(domain_path, rad_value_basename+'_lev'+str(level)+'.tif')\n",
    "    \n",
    "    #  --- PART 2. define inputs of discretization ---\n",
    "    # raster_list: a list of raster inputs that are used to define HRU.\n",
    "    # fieldname_list: a list of field names corresponding to raster_list.\n",
    "    \n",
    "    # level 0: GRU = HRU (benchmark). \n",
    "    if level == '0': \n",
    "        # (1) define input files for hru discretization\n",
    "        raster_list = [domain_gru_raster]\n",
    "        fieldname_list = [gruNo_field]  \n",
    "\n",
    "    # level 1: use only elevation bands in HRU generation.\n",
    "    if level == '1': \n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(domain_dem_raster, domain_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                           dem_class_raster, dem_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list = [domain_gru_raster,dem_class_raster]\n",
    "        fieldname_list = [gruNo_field, elev_class_field]\n",
    "    \n",
    "    # level 2a: use elevation bands and landcover classes in HRU generation.\n",
    "    elif level == '2a': \n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(domain_dem_raster, domain_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                           dem_class_raster, dem_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list = [domain_gru_raster, dem_class_raster, domain_landcover_class_raster]\n",
    "        fieldname_list = [gruNo_field, elev_class_field, land_class_field]\n",
    "\n",
    "    # level 2b: use elevation bands and radiation classes in HRU generation.\n",
    "    elif level == '2b': \n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(domain_dem_raster, domain_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                           dem_class_raster, dem_value_raster)        \n",
    "        # (2) classify radiation raster per gru\n",
    "        ga.classify_raster(domain_radiation_raster, domain_gru_raster, rad_classif_trigger, rad_bins, \n",
    "                           rad_class_raster, rad_value_raster)        \n",
    "        # (3) define input files for hru discretization\n",
    "        raster_list = [domain_gru_raster, dem_class_raster, rad_class_raster]\n",
    "        fieldname_list = [gruNo_field, elev_class_field, radiation_class_field]\n",
    "    \n",
    "    \n",
    "    # level 3a: use elevation bands, radiation bands, landcover classes in HRU generation.\n",
    "    elif level == '3a':\n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(domain_dem_raster, domain_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                           dem_class_raster, dem_value_raster)        \n",
    "        # (2) classify radiation raster per gru\n",
    "        ga.classify_raster(domain_radiation_raster, domain_gru_raster, rad_classif_trigger, rad_bins, \n",
    "                           rad_class_raster, rad_value_raster)        \n",
    "        # (3) define input files for hru discretization\n",
    "        raster_list = [domain_gru_raster, dem_class_raster, rad_class_raster, domain_landcover_class_raster]\n",
    "        fieldname_list = [gruNo_field, elev_class_field, radiation_class_field, land_class_field]\n",
    "\n",
    "    # level 3b: nested. radiation bands are generated based on level 2a HRU.\n",
    "    elif level == '3b':\n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(domain_dem_raster, domain_gru_raster, dem_classif_trigger, dem_bins, \n",
    "                                      dem_class_raster, dem_value_raster)        \n",
    "        # (2) classify radiation raster per level 2a hru\n",
    "        hru_lev2a_raster = os.path.join(domain_path, 'hru'+'_lev2a_elmn.tif')\n",
    "        ga.classify_raster(domain_radiation_raster, hru_lev2a_raster, rad_classif_trigger, rad_bins, \n",
    "                                      rad_class_raster, rad_value_raster)        \n",
    "        # (3) define input files for hru discretization\n",
    "        raster_list = [domain_gru_raster, dem_class_raster, rad_class_raster, domain_landcover_class_raster]\n",
    "        fieldname_list = [gruNo_field, elev_class_field, radiation_class_field, land_class_field]\n",
    "\n",
    "    # --- PART 3. genearte HRU based on gru and elevation class ---\n",
    "    ga.define_hru(raster_list, fieldname_list, domain_gru_raster, domain_gru_corr_txt, gruNo_field, gruName_field,\n",
    "                  hru_raster, hru_vector, hruNo_field, hruNo_field_dtype, hruName_field)\n",
    "\n",
    "    # --- PART 4. calculate HRU area ---\n",
    "    in_gpd = gpd.read_file(hru_vector)\n",
    "    in_gpd[hru_area_field] = in_gpd.area\n",
    "    in_gpd.to_file(hru_vector)\n",
    "\n",
    "    # --- PART 5. eliminate small area HRUs ---\n",
    "    # mehod 1: change HRU attribute to the most dominant HRU within the GRU. Use function ga.eliminate_small_hrus_dominant\n",
    "    # method 2: change HRU attribute to its' largest neighbor's HRU\n",
    "    ga.eliminate_small_hrus_neighbor(hru_vector, hru_thld_type, hru_thld, gruNo_field, gruName_field, \n",
    "                                     hruNo_field, hruNo_field_dtype, hruName_field, hru_area_field, \n",
    "                                     fieldname_list, refraster, \n",
    "                                     hru_vector_elmn, hru_raster_elmn)\n",
    "#     ga.plot_vector(hru_vector_elmn, hruName_field) # quick plot for check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Calculate HRU zonal statistics ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 2b ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:920: RuntimeWarning: invalid value encountered in sin\n",
      "  y = np.sin(np.radians(attr_smask)) # north/south vector (positive to N)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:921: RuntimeWarning: invalid value encountered in cos\n",
      "  x = np.cos(np.radians(attr_smask)) # west/east vector (positive to E)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:920: RuntimeWarning: invalid value encountered in sin\n",
      "  y = np.sin(np.radians(attr_smask)) # north/south vector (positive to N)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:921: RuntimeWarning: invalid value encountered in cos\n",
      "  x = np.cos(np.radians(attr_smask)) # west/east vector (positive to E)\n",
      "<ipython-input-8-5cfe523697e9>:97: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n",
      "<ipython-input-8-5cfe523697e9>:108: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n",
      "<ipython-input-8-5cfe523697e9>:116: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:920: RuntimeWarning: invalid value encountered in sin\n",
      "  y = np.sin(np.radians(attr_smask)) # north/south vector (positive to N)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:921: RuntimeWarning: invalid value encountered in cos\n",
      "  x = np.cos(np.radians(attr_smask)) # west/east vector (positive to E)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:920: RuntimeWarning: invalid value encountered in sin\n",
      "  y = np.sin(np.radians(attr_smask)) # north/south vector (positive to N)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:921: RuntimeWarning: invalid value encountered in cos\n",
      "  x = np.cos(np.radians(attr_smask)) # west/east vector (positive to E)\n",
      "<ipython-input-8-5cfe523697e9>:97: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n",
      "<ipython-input-8-5cfe523697e9>:108: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n",
      "<ipython-input-8-5cfe523697e9>:116: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "for level in level_list:\n",
    "\n",
    "    print('--- Complexity level %s ---' %(level))\n",
    "    \n",
    "    #  --- PART 1. define hru complexity level dependent files --- \n",
    "    hru_str = 'hru'+'_lev' + str(level)\n",
    "    hru_elmn_str = hru_str+'_elmn'     \n",
    "    \n",
    "    hru_vector = os.path.join(domain_path, hru_str+'.shp')\n",
    "    hru_vector_elmn = os.path.join(domain_path, hru_elmn_str+'.shp')    \n",
    "    \n",
    "    # --- PART 2. calculate zonal statistics ---\n",
    "    for invector in [hru_vector,hru_vector_elmn]:\n",
    "        \n",
    "        # (1) define invector dependent files \n",
    "        invector_field = hruNo_field\n",
    "        invector_field_dtype = hruNo_field_dtype\n",
    "        \n",
    "        attrb_elev = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_elevation.tif')        \n",
    "        attrb_slp = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_slope.tif')        \n",
    "        attrb_asp = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_aspect.tif')        \n",
    "        attrb_lc = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_landcover.tif')        \n",
    "        attrb_soil = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_soil.tif')        \n",
    "        \n",
    "        # (2) elevation zonal statistics \n",
    "        ga.zonal_statistic(domain_dem_raster, invector, invector_field, invector_field_dtype, \n",
    "                           refraster, 'mean', attrb_elev, output_column_prefix='elev')\n",
    "\n",
    "        # (3) slope zonal statistics \n",
    "        ga.zonal_statistic(domain_slope_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mean', attrb_slp, output_column_prefix='slope')\n",
    "\n",
    "        # (4) aspect zonal statistics \n",
    "        ga.zonal_statistic(domain_aspect_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mean_aspect', attrb_asp, output_column_prefix='aspect')\n",
    "\n",
    "        # (5) landcover zonal statistics \n",
    "        ga.zonal_statistic(domain_landcover_class_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mode', attrb_lc, output_column_prefix='vegType')        \n",
    "        \n",
    "        # (6) soil zonal statistics \n",
    "        ga.zonal_statistic(domain_soil_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mode', attrb_soil, output_column_prefix='soilType')        \n",
    "        \n",
    "        # -------- post-process attributes for SUMMA ---------\n",
    "        # (7) landcover and soil types \n",
    "        # convert landcover int to [1,17] range \n",
    "        # change soilType from float to int (because source soilType is float)\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['vegType'] = in_gpd['vegType']+1\n",
    "        in_gpd['soilType'] = in_gpd['soilType'].astype('int')\n",
    "        in_gpd.to_file(invector)\n",
    "        \n",
    "        # (8) convert landcover int to string for easy understanding\n",
    "        lcClass_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 255]\n",
    "        lcValue_list = ['Evergreen needleleaf forests', 'Evergreen broadleaf forests', 'Deciduous needleleaf forests',\n",
    "                        'Deciduous broadleaf forests', 'Mixed forests', 'Closed shrublands', 'Open shrublands', \n",
    "                        'Woody savannas', 'Savannas', 'Grasslands', 'Permanent wetlands', 'Croplands', \n",
    "                        'Urban and built-up lands', 'Cropland/natural vegetation mosaics', 'Snow and ice', \n",
    "                        'Barren', 'Water bodies', 'None']\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['landcover'] = \"\"\n",
    "        for irow, row in in_gpd.iterrows():\n",
    "            lcClass = in_gpd.loc[irow,'vegType'] \n",
    "            lcValue=lcValue_list[lcClass_list.index(lcClass)]\n",
    "            in_gpd.at[irow,'landcover'] = lcValue\n",
    "        in_gpd['landcover'] = in_gpd['landcover'].astype('str')\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (9) convert ROSETTA soil to STAS and add string for easy understanding\n",
    "        soilClass_list = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "        soilValue_list = ['OTHER(land-ice)', 'CLAY', 'CLAY LOAM', 'LOAM', 'LOAMY SAND', 'SAND', 'SANDY CLAY', \n",
    "                          'SANDY CLAY LOAM', 'SANDY LOAM', 'SILT','SILTY CLAY', 'SILTY CLAY LOAM', 'SILT LOAM']\n",
    "        soilClass_list_STAS = [16, 12, 9, 6, 2, 1, 10, 7, 3, 5, 11, 8, 4]\n",
    "        \n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['soilROSETTA'] = in_gpd['soilType']\n",
    "        in_gpd['soilSTAS'] = \"\"\n",
    "        in_gpd['soil'] = \"\"\n",
    "        for irow, row in in_gpd.iterrows():\n",
    "            \n",
    "            soilClass = in_gpd.loc[irow,'soilType'] \n",
    "            if soilClass==0:\n",
    "                lcClass = in_gpd.loc[irow,'vegType'] \n",
    "                print('hruNo = %d, soilType_ROSETTA = 0, and vegType = %s.'%(in_gpd.loc[irow,'hruNo'],lcClass))\n",
    "            \n",
    "            soilValue=soilValue_list[soilClass_list.index(soilClass)]\n",
    "            soilClass_STAS=soilClass_list_STAS[soilClass_list.index(soilClass)]\n",
    "            \n",
    "            in_gpd.at[irow,'soil'] = soilValue\n",
    "            in_gpd.at[irow,'soilSTAS'] = soilClass_STAS\n",
    "            \n",
    "        in_gpd['soil'] = in_gpd['soil'].astype('str')\n",
    "        in_gpd['soilSTAS'] = in_gpd['soilSTAS'].astype('int')\n",
    "        in_gpd['soilType'] = in_gpd['soilSTAS']\n",
    "        in_gpd = in_gpd.drop(columns=['soilSTAS'])\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (10) convert slope to tan_slope \n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['tan_slope'] = np.tan(np.radians(in_gpd['slope']))\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (11) calculate contourLength (meter)\n",
    "        # assuming the hru area is a circle and taking the radius as contourLength.\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['contourLength'] = np.power(in_gpd['areaSqm']/np.pi,0.5)\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (12) calculate centroid lat/lon (degree)\n",
    "        def getXY(pt):\n",
    "            return (pt.x, pt.y)\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd_wgs84 = in_gpd.copy()\n",
    "        in_gpd_wgs84 = in_gpd_wgs84.to_crs(epsg=4326) #\"EPSG:4326\"\n",
    "        centroidseries = in_gpd_wgs84['geometry'].centroid\n",
    "        in_gpd['longitude'],in_gpd['latitude']=[list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "    # --- PART 3. save HRU with attributes into gpkg ---\n",
    "    invector_gpkg = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'.gpkg')\n",
    "    in_gpd = gpd.read_file(invector)\n",
    "    in_gpd.to_file(invector_gpkg, driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate GRU zonal statistics (optional) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:920: RuntimeWarning: invalid value encountered in sin\n",
      "  y = np.sin(np.radians(attr_smask)) # north/south vector (positive to N)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:921: RuntimeWarning: invalid value encountered in cos\n",
      "  x = np.cos(np.radians(attr_smask)) # west/east vector (positive to E)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:920: RuntimeWarning: invalid value encountered in sin\n",
      "  y = np.sin(np.radians(attr_smask)) # north/south vector (positive to N)\n",
      "/Users/hongliliu/Documents/github/discretization/discretize/geospatial_functions/geospatial_analysis.py:921: RuntimeWarning: invalid value encountered in cos\n",
      "  x = np.cos(np.radians(attr_smask)) # west/east vector (positive to E)\n",
      "<ipython-input-14-55840c6bcbb2>:93: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n",
      "<ipython-input-14-55840c6bcbb2>:98: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n",
      "<ipython-input-14-55840c6bcbb2>:104: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-55840c6bcbb2>:112: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n",
      "<ipython-input-14-55840c6bcbb2>:114: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  in_gpd.to_file(invector)\n"
     ]
    }
   ],
   "source": [
    "invector = domain_gru_prj_shp\n",
    "invector_field = gruNo_field\n",
    "invector_field_dtype = gruNo_field_dtype\n",
    "\n",
    "attrb_elev = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_elevation.tif')        \n",
    "attrb_slp = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_slope.tif')        \n",
    "attrb_asp = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_aspect.tif')        \n",
    "attrb_lc = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_landcover.tif')        \n",
    "attrb_soil = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb_soil.tif')        \n",
    "\n",
    "outvector = os.path.join(domain_path, os.path.basename(invector).split('.shp')[0]+'_attrb.gpkg')     \n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd.to_file(outvector, driver=\"GPKG\")\n",
    "invector = outvector # avoid process gru_shp_prj. Work on gpkg.\n",
    "\n",
    "# (1) calculate zonal area ---\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['areaSqm'] = in_gpd.area\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (2) elevation zonal statistics \n",
    "ga.zonal_statistic(domain_dem_raster, invector, invector_field, invector_field_dtype, refraster, 'mean', attrb_elev,\n",
    "                   output_column_prefix='elev')\n",
    "\n",
    "# (3) slope zonal statistics \n",
    "ga.zonal_statistic(domain_slope_raster, invector, invector_field, invector_field_dtype, refraster, 'mean', attrb_slp,\n",
    "                   output_column_prefix='slope')\n",
    "\n",
    "# (4) aspect zonal statistics \n",
    "ga.zonal_statistic(domain_aspect_raster, invector, invector_field, invector_field_dtype, refraster, 'mean_aspect', attrb_asp,\n",
    "                   output_column_prefix='aspect')\n",
    "\n",
    "# (5) landcover zonal statistics \n",
    "ga.zonal_statistic(domain_landcover_class_raster, invector, invector_field, invector_field_dtype, refraster, 'mode', attrb_lc,\n",
    "                   output_column_prefix='vegType')        \n",
    "\n",
    "# (6) soil zonal statistics \n",
    "ga.zonal_statistic(domain_soil_raster, invector, invector_field, invector_field_dtype, refraster, 'mode', attrb_soil,\n",
    "                   output_column_prefix='soilType')        \n",
    "\n",
    "# -------- post-process attributes for SUMMA ---------\n",
    "# (7) landcover and soil types \n",
    "# convert landcover int to [1,17] range \n",
    "# change soilType from float to int (because source soilType is float)\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['vegType'] = in_gpd['vegType']+1\n",
    "in_gpd['soilType'] = in_gpd['soilType'].astype('int')\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (8) convert landcover int to string for easy understanding\n",
    "lcClass_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 255]\n",
    "lcValue_list = ['Evergreen needleleaf forests', 'Evergreen broadleaf forests', 'Deciduous needleleaf forests',\n",
    "                'Deciduous broadleaf forests', 'Mixed forests', 'Closed shrublands', 'Open shrublands', \n",
    "                'Woody savannas', 'Savannas', 'Grasslands', 'Permanent wetlands', 'Croplands', \n",
    "                'Urban and built-up lands', 'Cropland/natural vegetation mosaics', 'Snow and ice', \n",
    "                'Barren', 'Water bodies', 'None']\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['landcover'] = \"\"\n",
    "for irow, row in in_gpd.iterrows():\n",
    "    lcClass = in_gpd.loc[irow,'vegType'] \n",
    "    lcValue=lcValue_list[lcClass_list.index(lcClass)]\n",
    "    in_gpd.at[irow,'landcover'] = lcValue\n",
    "in_gpd['landcover'] = in_gpd['landcover'].astype('str')\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (9) convert ROSETTA soil to STAS and add string for easy understanding\n",
    "soilClass_list = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "soilValue_list = ['OTHER(land-ice)', 'CLAY', 'CLAY LOAM', 'LOAM', 'LOAMY SAND', 'SAND', 'SANDY CLAY', \n",
    "                  'SANDY CLAY LOAM', 'SANDY LOAM', 'SILT','SILTY CLAY', 'SILTY CLAY LOAM', 'SILT LOAM']\n",
    "soilClass_list_STAS = [16, 12, 9, 6, 2, 1, 10, 7, 3, 5, 11, 8, 4]\n",
    "\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['soilROSETTA'] = in_gpd['soilType']\n",
    "in_gpd['soilSTAS'] = \"\"\n",
    "in_gpd['soil'] = \"\"\n",
    "for irow, row in in_gpd.iterrows():\n",
    "\n",
    "    soilClass = in_gpd.loc[irow,'soilType'] \n",
    "    if soilClass==0:\n",
    "        lcClass = in_gpd.loc[irow,'vegType'] \n",
    "        print('hruNo = %d, soilType_ROSETTA = 0, and vegType = %s.'%(in_gpd.loc[irow,'hruNo'],lcClass))\n",
    "\n",
    "    soilValue=soilValue_list[soilClass_list.index(soilClass)]\n",
    "    soilClass_STAS=soilClass_list_STAS[soilClass_list.index(soilClass)]\n",
    "\n",
    "    in_gpd.at[irow,'soil'] = soilValue\n",
    "    in_gpd.at[irow,'soilSTAS'] = soilClass_STAS\n",
    "\n",
    "in_gpd['soil'] = in_gpd['soil'].astype('str')\n",
    "in_gpd['soilSTAS'] = in_gpd['soilSTAS'].astype('int')\n",
    "in_gpd['soilType'] = in_gpd['soilSTAS']\n",
    "in_gpd = in_gpd.drop(columns=['soilSTAS'])\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (10) convert slope to tan_slope \n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['tan_slope'] = np.tan(np.radians(in_gpd['slope']))\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (11) calculate contourLength (meter)\n",
    "# assuming the hru area is a circle and taking the radius as contourLength.\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['contourLength'] = np.power(in_gpd['areaSqm']/np.pi,0.5)\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (12) calculate centroid lat/lon (degree)\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd_wgs84 = in_gpd.copy()\n",
    "in_gpd_wgs84 = in_gpd_wgs84.to_crs(epsg=4326) #\"EPSG:4326\"\n",
    "centroidseries = in_gpd_wgs84['geometry'].centroid\n",
    "in_gpd['longitude'],in_gpd['latitude']=[list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "in_gpd.to_file(invector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summa-env",
   "language": "python",
   "name": "summa-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
