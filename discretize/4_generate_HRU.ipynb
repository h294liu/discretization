{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1. Import libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "from sys import exit\n",
    "import geospatial_functions.geospatial_analysis as ga\n",
    "from osgeo import gdal\n",
    "from rasterio.warp import Resampling\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2. Specify file paths ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# ================ INPUTS AND CONFIGURATIONS (EDITION NEEDED) ================ \n",
    "# --- PART 1. common input files ---\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_06_02HRUcomplexity/discretize'\n",
    "# root_dir='/Users/hongli/Documents/proj/2020_06_01HRUcomplexity/discretize'\n",
    "source_data_dir = os.path.join(root_dir, 'source_data')\n",
    "\n",
    "huc12_shp = os.path.join(source_data_dir, 'west_huc12/WEST.huc12.shp')\n",
    "huc12_field   = 'HUC12' #'HUC12int'     \n",
    "Tohuc12_field = 'ToHUC'\n",
    "\n",
    "dem_raster = os.path.join(source_data_dir, 'MERIT_Hydro_dem_NLDAS.tif') # large-domain DEM raster covering the case study area. Used for clipping.\n",
    "dem_nodatavalue = -9999                                                 # the value for pixels to be considered as NoData. Obtained by checking dem_raster.\n",
    "\n",
    "lc_raster = os.path.join(source_data_dir, 'nldas_landcover.tif')        # silimar with dem_raster, but for landcover.\n",
    "lc_nodatavalue = 255                                                    # silimar with dem_nodatavalue.\n",
    "\n",
    "soil_raster = os.path.join(source_data_dir, 'usda_mode_soilclass_vCompressed_NA_250m_ll.tif') # silimar with dem_raster, but for soil.\n",
    "soil_nodatavalue = np.nan                                               # silimar with dem_nodatavalue.\n",
    "    \n",
    "# ---- PART 2. case study relevant inputs and configurations ----\n",
    "case = 'shoshone'                                                # user-specified case study name. Used to create a case study foler to store all the case study relevant files.\n",
    "outlet_hucid = '100800120304'                                    # huc12id of the outlet HUC12 of the case study area.\n",
    "# case = 'tuolumne'\n",
    "# outlet_hucid = '180400090504'\n",
    "\n",
    "case_dir = os.path.join(root_dir, case)                          # case study directory. Used to store all the case study relevant files.\n",
    "if not os.path.exists(case_dir): os.makedirs(case_dir)           # create case study folder if it doesn't exist.\n",
    "rad_raster = os.path.join(case_dir, 'step9_merge_raw_Sw/sw.tif') # solar radiation raster for case study. Calcualted based on the reference: Allen et al., 2006. Agricultural and Forest Meteorology. \n",
    "\n",
    "# ---- PART 3. define GRU and HRU field names and data types ----\n",
    "# note: Some avaialble dtypes for rasterio: 'int16', 'int32', 'float32', 'float64'. No 'int64'!\n",
    "# reference: https://test2.biogeo.ucdavis.edu/rasterio/_modules/rasterio/dtypes.html\n",
    "gruNo_field = 'gruNo'       # field name of gru number, e.g.,1,2,3...\n",
    "gruNo_field_dtype = 'int32' # used to save gruNo raster. \n",
    "gruName_field = 'gruId'     # field name of gru name, e.g., 100800120101. \n",
    "\n",
    "hruNo_field = 'hruNo'       # field name of hru number, e.g.,1,2,3...\n",
    "hruNo_field_dtype = 'int32' # used to save hruNo raster. \n",
    "hruName_field = 'hruId'     # field name of hru name, e.g., 10080012010101, 100800120102. \n",
    "hruArea_field = 'areaSqm'   # field name of hru area, used in small HRU elimination\n",
    "\n",
    "# ---- PART 4. define common projection, nodata value, reference raster ----\n",
    "proj4=\"+proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\"\n",
    "dst_crs = rio.crs.CRS.from_string(proj4)\n",
    "## Albers Equal Area Conic Projection. \n",
    "## reference 1: https://gisgeography.com/conic-projection-lambert-albers-polyconic/\n",
    "## reference 2: https://epsg.io/102008\n",
    "\n",
    "nodatavalue = -9999   # used in raster generatation\n",
    "\n",
    "# ---- PART 5. define HRU elimination threshold (two options: value, fraction) ----\n",
    "# hru_thld_type = 'value'\n",
    "# hru_thld = 10**6 #1km2\n",
    "\n",
    "hru_thld_type = 'fraction'\n",
    "hru_thld = 0.05  # partial of the gru area\n",
    "\n",
    "\n",
    "# ================ INTERMEDIATE FILES (NO EDITION NEEDED) ================ \n",
    "dem_raster_prj = os.path.join(os.path.dirname(dem_raster), os.path.basename(dem_raster).split('.tif')[0]+'_prj.tif')\n",
    "lc_raster_prj = os.path.join(os.path.dirname(lc_raster), os.path.basename(lc_raster).split('.tif')[0]+'_prj.tif')\n",
    "soil_raster_prj = os.path.join(os.path.dirname(soil_raster), os.path.basename(soil_raster).split('.tif')[0]+'_prj.tif')\n",
    "\n",
    "dem_crop = os.path.join(case_dir, 'dem_crop.tif')               # DEM raster of case study. Cropped from the projected large-domain DEM raster.\n",
    "refraster = dem_crop                                            # reference raster, used in vector rasterization and resample.\n",
    "dem_crop_buf = os.path.join(case_dir, 'dem_crop_buf.tif')       # buffered DEM raster of case study. \n",
    "dem_class_raster_basename = os.path.join(case_dir, 'dem_class') # basename for DEM class files (e.g., 0:low elevation. 1: high elevation).\n",
    "dem_value_raster_basename = os.path.join(case_dir, 'dem_value') # basename for DEM value files (e.g., average DEM per class).\n",
    "\n",
    "slope_raster = os.path.join(case_dir, 'slope.tif')             # slope raster, calcualted based on dem_crop.\n",
    "aspect_raster = os.path.join(case_dir, 'aspect.tif')           # aspect raster, calcualted based on dem_crop.\n",
    "\n",
    "lc_crop = os.path.join(case_dir, 'landcover_crop.tif')         # landcover raster of case study. Cropped from the projected large-domain landcover raster.\n",
    "lc_crop_resample = os.path.join(case_dir, 'landcover_crop_resample.tif') # resampled landcover raster according to the layout of refraster. \n",
    "lc_class_raster = os.path.join(case_dir, 'landcover_class.tif')# landcover class raster (e.g., canopy, non-canopy).\n",
    "\n",
    "soil_crop = os.path.join(case_dir, 'soil_crop.tif')         # soil raster of case study.\n",
    "\n",
    "gru_shp = os.path.join(case_dir, 'huc12.shp')               # GRU shapefile of case study. Cropped from the large-domain HUC12 shapefile.\n",
    "huc12_list_txt = 'huc12Ids.txt'                                    # list of HUC12 ids.\n",
    "gru_shp_prj = os.path.join(case_dir, 'gru_prj.shp')         # project GRU shapefile.\n",
    "gru_raster = os.path.join(case_dir, 'gru.tif')              # project GRU raster file.\n",
    "gru_corr_txt=os.path.join(case_dir, 'gruNo_HUC12_corr.txt') # correspondence between HUC12 and gru number (for recrod).\n",
    " \n",
    "rad_class_raster_basename = os.path.join(case_dir, 'rad_class') # basename for radiation class files (e.g., 0:low. 1:high).\n",
    "rad_value_raster_basename = os.path.join(case_dir, 'rad_value') # basename for radiation value files (e.g., average radiation per class).\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3. Generate HRU at different complexity levels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 0 ---\n",
      "PART 1. define files\n",
      "PART 2. genearte HRU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 546.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 3. calculate zonal area\n",
      "PART 4. eliminate small HRUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 5. calculate zonal statistics \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5521acb113e1>:202: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 1 ---\n",
      "PART 1. define files\n",
      "PART 2. genearte HRU\n",
      "PART 3. calculate zonal area\n",
      "PART 4. eliminate small HRUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 555.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 5. calculate zonal statistics \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5521acb113e1>:202: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 2 ---\n",
      "PART 1. define files\n",
      "PART 2. genearte HRU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 3. calculate zonal area\n",
      "PART 4. eliminate small HRUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 5. calculate zonal statistics \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5521acb113e1>:202: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 3 ---\n",
      "PART 1. define files\n",
      "PART 2. genearte HRU\n",
      "PART 3. calculate zonal area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 4. eliminate small HRUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:11<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 5. calculate zonal statistics \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5521acb113e1>:202: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 4 ---\n",
      "PART 1. define files\n",
      "PART 2. genearte HRU\n",
      "PART 3. calculate zonal area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 4. eliminate small HRUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:08<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 5. calculate zonal statistics \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5521acb113e1>:202: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "level_num = 4 #3\n",
    "for level in range(1+level_num):\n",
    "# for level in range(3):\n",
    "\n",
    "    print('--- Complexity level %d ---' %(level))\n",
    "    \n",
    "    #  --- PART 1. define hru complexity level dependent files --- \n",
    "    print('PART 1. define files')\n",
    "    hru_str = 'hru'+'_lev' + str(level)\n",
    "    hru_elmn_str = hru_str+'_elmn'       \n",
    "    hru_raster = os.path.join(case_dir, hru_str+'.tif')            # original HRU\n",
    "    hru_vector = os.path.join(case_dir, hru_str+'.shp')\n",
    "    hru_raster_elmn = os.path.join(case_dir, hru_elmn_str+'.tif')  # simplified HRU\n",
    "    hru_vector_elmn = os.path.join(case_dir, hru_elmn_str+'.shp')    \n",
    "\n",
    "    dem_classif_trigger = 300 # Elvation difference value of triggering classification.\n",
    "    dem_bins = 'median'\n",
    "    dem_class_raster=dem_class_raster_basename+'_lev'+str(level)+'.tif'\n",
    "    dem_value_raster=dem_value_raster_basename+'_lev'+str(level)+'.tif'\n",
    "    \n",
    "    rad_classif_trigger = None\n",
    "    rad_bins = 'median'\n",
    "    rad_class_raster=rad_class_raster_basename+'_lev'+str(level)+'.tif'\n",
    "    rad_value_raster=rad_value_raster_basename+'_lev'+str(level)+'.tif'\n",
    "    \n",
    "    # level 0: GRU = HRU \n",
    "    if level == 0: \n",
    "        # define hru discretization files\n",
    "        raster_list = [gru_raster]\n",
    "        raster_fieldname_list = [gruNo_field]\n",
    "\n",
    "    # level 1: use only elevation bands in HRU generation\n",
    "    if level == 1: \n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_continuous_raster(dem_crop, gru_raster, dem_classif_trigger, dem_bins, \n",
    "                                      dem_class_raster, dem_value_raster, nodatavalue)        \n",
    "        # (2) define hru discretization files\n",
    "        raster_list = [gru_raster,dem_class_raster]\n",
    "        raster_fieldname_list = [gruNo_field,'elevClass']\n",
    "    \n",
    "    # level 2: use elevation bands and landcover classes in HRU generation\n",
    "    elif level == 2: \n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_continuous_raster(dem_crop, gru_raster, dem_classif_trigger, dem_bins, \n",
    "                                      dem_class_raster, dem_value_raster, nodatavalue)        \n",
    "        # (2) define hru discretization files\n",
    "        raster_list = [gru_raster, dem_class_raster, lc_class_raster]\n",
    "        raster_fieldname_list = [gruNo_field, 'elevClass', 'lcClass']\n",
    "    \n",
    "     # level 3: use elevation bands, radiation bands, landcover classes in HRU generation\n",
    "    elif level == 3:\n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_continuous_raster(dem_crop, gru_raster, dem_classif_trigger, dem_bins, \n",
    "                                      dem_class_raster, dem_value_raster, nodatavalue)        \n",
    "        # (2) classify radiation raster per gru\n",
    "        ga.classify_continuous_raster(rad_raster, gru_raster, rad_classif_trigger, rad_bins, \n",
    "                                      rad_class_raster, rad_value_raster, nodatavalue)        \n",
    "        # (3) define hru discretization files\n",
    "        raster_list = [gru_raster, dem_class_raster, rad_class_raster, lc_class_raster]\n",
    "        raster_fieldname_list = [gruNo_field, 'elevClass', 'radClass', 'lcClass']\n",
    "\n",
    "     # level 4: radiation bands are generated based on level2 HRU, add radiation bands to level2 HRU\n",
    "    elif level == 4:\n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_continuous_raster(dem_crop, gru_raster, dem_classif_trigger, dem_bins, \n",
    "                                      dem_class_raster, dem_value_raster, nodatavalue)        \n",
    "        # (2) classify radiation raster per level2 hru\n",
    "        hru_lev2_raster = os.path.join(case_dir, 'hru'+'_lev' + str(2)+'_elmn.tif')\n",
    "        ga.classify_continuous_raster(rad_raster, hru_lev2_raster, rad_classif_trigger, rad_bins, \n",
    "                                      rad_class_raster, rad_value_raster, nodatavalue)        \n",
    "        # (3) define hru discretization files\n",
    "        raster_list = [gru_raster, dem_class_raster, rad_class_raster, lc_class_raster]\n",
    "        raster_fieldname_list = [gruNo_field, 'elevClass', 'radClass', 'lcClass']\n",
    "\n",
    "#         # (2) define hru discretization files\n",
    "#         raster_list = [gru_raster, hru_lev2_raster, rad_class_raster]\n",
    "#         raster_fieldname_list = [gruNo_field, 'hruLev2', 'radClass']\n",
    "\n",
    "    # --- PART 2. genearte HRU based on gru and elevation class ---\n",
    "    print('PART 2. genearte HRU')\n",
    "    ga.define_hru(raster_list, raster_fieldname_list, gru_raster, gru_corr_txt, gruNo_field, gruName_field,\n",
    "                  nodatavalue, hru_raster, hru_vector, hruNo_field, hruNo_field_dtype, hruName_field)\n",
    "#     ga.plot_vector(hru_vector, hruName_field) # quick plot for check\n",
    "\n",
    "    # --- PART 3. calculate zonal area ---\n",
    "    print('PART 3. calculate zonal area')\n",
    "    in_gpd = gpd.read_file(hru_vector)\n",
    "    in_gpd['areaSqm'] = in_gpd.area\n",
    "    in_gpd.to_file(hru_vector)\n",
    "\n",
    "    # --- PART 4. eliminate small HRUs ---\n",
    "    print('PART 4. eliminate small HRUs')\n",
    "    # method 2: change HRU attribute to its' largest neighbor's HRU\n",
    "    ga.eliminate_small_hrus_neighbor(hru_vector, hru_thld_type, hru_thld, gruNo_field, gruName_field, hruNo_field, hruNo_field_dtype, \n",
    "                                     hruName_field, hruArea_field, raster_fieldname_list, refraster, hru_vector_elmn, hru_raster_elmn,\n",
    "                                     nodatavalue)\n",
    "\n",
    "    # --- PART 5. calculate zonal statistics ---\n",
    "    print('PART 5. calculate zonal statistics ')\n",
    "    for invector in [hru_vector,hru_vector_elmn]:\n",
    "        \n",
    "        # (1) define invector dependent files \n",
    "        invector_field = hruNo_field\n",
    "        invector_field_dtype = hruNo_field_dtype\n",
    "        attrb_elev = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_elevation.tif')        \n",
    "        attrb_slp = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_slope.tif')        \n",
    "        attrb_asp = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_aspect.tif')        \n",
    "        attrb_lc = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_landcover.tif')        \n",
    "        attrb_soil = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_soil.tif')        \n",
    "        \n",
    "        # (2) elevation zonal statistics \n",
    "        ga.zonal_statistic(dem_crop, invector, invector_field, invector_field_dtype, refraster, 'mean', attrb_elev,\n",
    "                           nodatavalue, output_column_prefix='elev')\n",
    "\n",
    "        # (3) slope zonal statistics \n",
    "        ga.zonal_statistic(slope_raster, invector, invector_field, invector_field_dtype, refraster, 'mean', attrb_slp,\n",
    "                           nodatavalue, output_column_prefix='slope')\n",
    "\n",
    "        # (4) aspect zonal statistics \n",
    "        ga.zonal_statistic(aspect_raster, invector, invector_field, invector_field_dtype, refraster, 'mean_aspect', attrb_asp,\n",
    "                           nodatavalue, output_column_prefix='aspect')\n",
    "\n",
    "        # (5) landcover zonal statistics \n",
    "        ga.zonal_statistic(lc_crop_resample, invector, invector_field, invector_field_dtype, refraster, 'mode', attrb_lc,\n",
    "                           nodatavalue, output_column_prefix='vegType')        \n",
    "        \n",
    "        # (6) soil zonal statistics \n",
    "        ga.zonal_statistic(soil_crop, invector, invector_field, invector_field_dtype, refraster, 'mode', attrb_soil,\n",
    "                           nodatavalue, output_column_prefix='soilType')        \n",
    "        \n",
    "        # -------- post-process attributes for SUMMA ---------\n",
    "        # (7) landcover and soil types \n",
    "        # convert landcover int to [1,17] range \n",
    "        # change soilType from float to int (because source soilType is float)\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['vegType'] = in_gpd['vegType']+1\n",
    "        in_gpd['soilType'] = in_gpd['soilType'].astype('int')\n",
    "        in_gpd.to_file(invector)\n",
    "        \n",
    "        # (8) convert landcover int to string for easy understanding\n",
    "        lcClass_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 255]\n",
    "        lcValue_list = ['Evergreen needleleaf forests', 'Evergreen broadleaf forests', 'Deciduous needleleaf forests',\n",
    "                        'Deciduous broadleaf forests', 'Mixed forests', 'Closed shrublands', 'Open shrublands', \n",
    "                        'Woody savannas', 'Savannas', 'Grasslands', 'Permanent wetlands', 'Croplands', \n",
    "                        'Urban and built-up lands', 'Cropland/natural vegetation mosaics', 'Snow and ice', \n",
    "                        'Barren', 'Water bodies', 'None']\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['landcover'] = \"\"\n",
    "        for irow, row in in_gpd.iterrows():\n",
    "            lcClass = in_gpd.loc[irow,'vegType'] \n",
    "            lcValue=lcValue_list[lcClass_list.index(lcClass)]\n",
    "            in_gpd.at[irow,'landcover'] = lcValue\n",
    "        in_gpd['landcover'] = in_gpd['landcover'].astype('str')\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (9) convert ROSETTA soil to STAS and add string for easy understanding\n",
    "        soilClass_list = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "        soilValue_list = ['OTHER(land-ice)', 'CLAY', 'CLAY LOAM', 'LOAM', 'LOAMY SAND', 'SAND', 'SANDY CLAY', \n",
    "                          'SANDY CLAY LOAM', 'SANDY LOAM', 'SILT','SILTY CLAY', 'SILTY CLAY LOAM', 'SILT LOAM']\n",
    "        soilClass_list_STAS = [16, 12, 9, 6, 2, 1, 10, 7, 3, 5, 11, 8, 4]\n",
    "        \n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['soilROSETTA'] = in_gpd['soilType']\n",
    "        in_gpd['soilSTAS'] = \"\"\n",
    "        in_gpd['soil'] = \"\"\n",
    "        for irow, row in in_gpd.iterrows():\n",
    "            \n",
    "            soilClass = in_gpd.loc[irow,'soilType'] \n",
    "            if soilClass==0:\n",
    "                lcClass = in_gpd.loc[irow,'vegType'] \n",
    "                print('hruNo = %d, soilType_ROSETTA = 0, and vegType = %s.'%(in_gpd.loc[irow,'hruNo'],lcClass))\n",
    "            \n",
    "            soilValue=soilValue_list[soilClass_list.index(soilClass)]\n",
    "            soilClass_STAS=soilClass_list_STAS[soilClass_list.index(soilClass)]\n",
    "            \n",
    "            in_gpd.at[irow,'soil'] = soilValue\n",
    "            in_gpd.at[irow,'soilSTAS'] = soilClass_STAS\n",
    "            \n",
    "        in_gpd['soil'] = in_gpd['soil'].astype('str')\n",
    "        in_gpd['soilSTAS'] = in_gpd['soilSTAS'].astype('int')\n",
    "        in_gpd['soilType'] = in_gpd['soilSTAS']\n",
    "        in_gpd = in_gpd.drop(columns=['soilSTAS'])\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (10) convert slope to tan_slope \n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['tan_slope'] = np.tan(np.radians(in_gpd['slope']))\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (11) calculate contourLength (meter)\n",
    "        # assuming the hru area is a circle and taking the radius as contourLength.\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd['contourLength'] = np.power(in_gpd['areaSqm']/np.pi,0.5)\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (12) calculate centroid lat/lon (degree)\n",
    "        def getXY(pt):\n",
    "            return (pt.x, pt.y)\n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        in_gpd_wgs84 = in_gpd.copy()\n",
    "        in_gpd_wgs84 = in_gpd_wgs84.to_crs(epsg=4326) #\"EPSG:4326\"\n",
    "        centroidseries = in_gpd_wgs84['geometry'].centroid\n",
    "        in_gpd['longitude'],in_gpd['latitude']=[list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "    # --- PART 6. save as gpkg ---\n",
    "    invector_gpkg = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'.gpkg')\n",
    "    in_gpd = gpd.read_file(invector)\n",
    "    in_gpd.to_file(invector_gpkg, driver=\"GPKG\")\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4. Calculate GRU attributes (if needed) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-6a40edc99525>:112: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidseries = in_gpd_wgs84['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "invector = gru_shp_prj\n",
    "invector_field = gruNo_field\n",
    "invector_field_dtype = gruNo_field_dtype\n",
    "\n",
    "attrb_elev = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_elevation.tif')        \n",
    "attrb_slp = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_slope.tif')        \n",
    "attrb_asp = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_aspect.tif')        \n",
    "attrb_lc = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_landcover.tif')        \n",
    "attrb_soil = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb_soil.tif')        \n",
    "\n",
    "outvector = os.path.join(case_dir, os.path.basename(invector).split('.shp')[0]+'_attrb.gpkg')     \n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd.to_file(outvector, driver=\"GPKG\")\n",
    "invector = outvector # avoid process gru_shp_prj. Work on gpkg.\n",
    "\n",
    "# (1) calculate zonal area ---\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['areaSqm'] = in_gpd.area\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (2) elevation zonal statistics \n",
    "ga.zonal_statistic(dem_crop, invector, invector_field, invector_field_dtype, refraster, 'mean', attrb_elev,\n",
    "                   nodatavalue, output_column_prefix='elev')\n",
    "\n",
    "# (3) slope zonal statistics \n",
    "ga.zonal_statistic(slope_raster, invector, invector_field, invector_field_dtype, refraster, 'mean', attrb_slp,\n",
    "                   nodatavalue, output_column_prefix='slope')\n",
    "\n",
    "# (4) aspect zonal statistics \n",
    "ga.zonal_statistic(aspect_raster, invector, invector_field, invector_field_dtype, refraster, 'mean_aspect', attrb_asp,\n",
    "                   nodatavalue, output_column_prefix='aspect')\n",
    "\n",
    "# (5) landcover zonal statistics \n",
    "ga.zonal_statistic(lc_crop_resample, invector, invector_field, invector_field_dtype, refraster, 'mode', attrb_lc,\n",
    "                   nodatavalue, output_column_prefix='vegType')        \n",
    "\n",
    "# (6) soil zonal statistics \n",
    "ga.zonal_statistic(soil_crop, invector, invector_field, invector_field_dtype, refraster, 'mode', attrb_soil,\n",
    "                   nodatavalue, output_column_prefix='soilType')        \n",
    "\n",
    "# -------- post-process attributes for SUMMA ---------\n",
    "# (7) landcover and soil types \n",
    "# convert landcover int to [1,17] range \n",
    "# change soilType from float to int (because source soilType is float)\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['vegType'] = in_gpd['vegType']+1\n",
    "in_gpd['soilType'] = in_gpd['soilType'].astype('int')\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (8) convert landcover int to string for easy understanding\n",
    "lcClass_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 255]\n",
    "lcValue_list = ['Evergreen needleleaf forests', 'Evergreen broadleaf forests', 'Deciduous needleleaf forests',\n",
    "                'Deciduous broadleaf forests', 'Mixed forests', 'Closed shrublands', 'Open shrublands', \n",
    "                'Woody savannas', 'Savannas', 'Grasslands', 'Permanent wetlands', 'Croplands', \n",
    "                'Urban and built-up lands', 'Cropland/natural vegetation mosaics', 'Snow and ice', \n",
    "                'Barren', 'Water bodies', 'None']\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['landcover'] = \"\"\n",
    "for irow, row in in_gpd.iterrows():\n",
    "    lcClass = in_gpd.loc[irow,'vegType'] \n",
    "    lcValue=lcValue_list[lcClass_list.index(lcClass)]\n",
    "    in_gpd.at[irow,'landcover'] = lcValue\n",
    "in_gpd['landcover'] = in_gpd['landcover'].astype('str')\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (9) convert ROSETTA soil to STAS and add string for easy understanding\n",
    "soilClass_list = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "soilValue_list = ['OTHER(land-ice)', 'CLAY', 'CLAY LOAM', 'LOAM', 'LOAMY SAND', 'SAND', 'SANDY CLAY', \n",
    "                  'SANDY CLAY LOAM', 'SANDY LOAM', 'SILT','SILTY CLAY', 'SILTY CLAY LOAM', 'SILT LOAM']\n",
    "soilClass_list_STAS = [16, 12, 9, 6, 2, 1, 10, 7, 3, 5, 11, 8, 4]\n",
    "\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['soilROSETTA'] = in_gpd['soilType']\n",
    "in_gpd['soilSTAS'] = \"\"\n",
    "in_gpd['soil'] = \"\"\n",
    "for irow, row in in_gpd.iterrows():\n",
    "\n",
    "    soilClass = in_gpd.loc[irow,'soilType'] \n",
    "    if soilClass==0:\n",
    "        lcClass = in_gpd.loc[irow,'vegType'] \n",
    "        print('hruNo = %d, soilType_ROSETTA = 0, and vegType = %s.'%(in_gpd.loc[irow,'hruNo'],lcClass))\n",
    "\n",
    "    soilValue=soilValue_list[soilClass_list.index(soilClass)]\n",
    "    soilClass_STAS=soilClass_list_STAS[soilClass_list.index(soilClass)]\n",
    "\n",
    "    in_gpd.at[irow,'soil'] = soilValue\n",
    "    in_gpd.at[irow,'soilSTAS'] = soilClass_STAS\n",
    "\n",
    "in_gpd['soil'] = in_gpd['soil'].astype('str')\n",
    "in_gpd['soilSTAS'] = in_gpd['soilSTAS'].astype('int')\n",
    "in_gpd['soilType'] = in_gpd['soilSTAS']\n",
    "in_gpd = in_gpd.drop(columns=['soilSTAS'])\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (10) convert slope to tan_slope \n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['tan_slope'] = np.tan(np.radians(in_gpd['slope']))\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (11) calculate contourLength (meter)\n",
    "# assuming the hru area is a circle and taking the radius as contourLength.\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd['contourLength'] = np.power(in_gpd['areaSqm']/np.pi,0.5)\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "# (12) calculate centroid lat/lon (degree)\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "in_gpd = gpd.read_file(invector)\n",
    "in_gpd_wgs84 = in_gpd.copy()\n",
    "in_gpd_wgs84 = in_gpd_wgs84.to_crs(epsg=4326) #\"EPSG:4326\"\n",
    "centroidseries = in_gpd_wgs84['geometry'].centroid\n",
    "in_gpd['longitude'],in_gpd['latitude']=[list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "in_gpd.to_file(invector)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
