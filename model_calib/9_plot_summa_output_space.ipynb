{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compare route outputs from different levels of complexity\n",
    "import os, datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm \n",
    "\n",
    "# ========== User settings ==================================\n",
    "root_dir='/glade/u/home/hongli/scratch/2020_06_02HRUcomplexity/model'\n",
    "basinName='06279940'\n",
    "\n",
    "# hru inputs\n",
    "level_num=0 #3\n",
    "label_basename='hru_lev'\n",
    "\n",
    "# hru shapefile\n",
    "case = 'shoshone'\n",
    "discretize_dir = '/glade/u/home/hongli/scratch/2020_06_02HRUcomplexity/discretize'\n",
    "case_dir = os.path.join(discretize_dir,case)\n",
    "sub_shp_prj = os.path.join(discretize_dir, case, 'subbasin_prj.shp')\n",
    "stream_clip = os.path.join(discretize_dir, case, 'stream.shp')\n",
    "wgs_crs = 'epsg:4326'\n",
    "\n",
    "# plot inputs\n",
    "time_format = '%Y-%m-%d'\n",
    "plot_date_start = '2007-10-01' #'2007-10-01'\n",
    "plot_date_end = '2008-09-30'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "plot_date_range = pd.date_range(start=plot_date_start,end=plot_date_end,freq='M').to_pydatetime().tolist()\n",
    "\n",
    "# temperature, precipitation, radiation, SWE, SM, ET, totalrunoff\n",
    "var_names_summa = ['spectralIncomingDirect_mean', 'spectralIncomingDiffuse_mean','pptrate_mean', 'airtemp_mean', 'scalarCanopyWat', 'scalarSWE', 'scalarAquiferStorage', \n",
    "                  'scalarTotalSoilWat','scalarSurfaceRunoff_mean',  'scalarAquiferBaseflow_mean', 'scalarTotalET_mean', 'scalarTotalRunoff_mean'] \n",
    "var_units_summa = ['$(W/m^2)$','$(W/m^2)$','kg m-2 s-1', 'K', 'kg m-2', 'kg m-2','m', 'kg m-2', 'm s-1', 'm s-1', 'kg m-2 s-1', 'm s-1']  \n",
    "\n",
    "var_names_plot = ['Direct Shortwave Rad','Diffuse Shortwave Rad','Precip Rate', 'Temprature', 'Canopy Water', 'SWE', 'Aquifer Storage', \n",
    "                 'Total Soil Water','Surface Runoff', 'Aquifer Baseflow', 'Total ET', 'Total Runoff']  \n",
    "var_units_plot = ['$(W/m^2)$','$(W/m^2)$','(mm/d)', '$(^\\circ$C)', '(mm)', '(mm)','(mm)', '(mm)', '(mm/d)', '(mm/d)', '(mm/d)', '(mm/d)'] \n",
    "\n",
    "output_dir=os.path.join(root_dir,basinName,'analysis/9_plot_summa_output_space')\n",
    "for level_id in range(level_num+1):\n",
    "    label=label_basename+str(level_id)\n",
    "    output_subdir=os.path.join(output_dir,label)\n",
    "    if not os.path.exists(output_subdir):\n",
    "        os.makedirs(output_subdir)\n",
    "\n",
    "# ========== end User settings ==================================\n",
    "\n",
    "# ##============== PART 1. Read data ==============\n",
    "# # --- read summa input & output\n",
    "# print('read')\n",
    "# data_dic = {}\n",
    "# var_units_update = []\n",
    "# for level_id in range(level_num+1):\n",
    "#     label=label_basename+str(level_id)\n",
    "#     data_lev_dic = {}\n",
    "    \n",
    "#     # (2) read other variables from summa output\n",
    "#     q_ncfile = os.path.join(root_dir,basinName,'output',label,'wbout_day.nc')\n",
    "#     ds = xr.open_dataset(q_ncfile) \n",
    "#     time = ds['time'].values[:]\n",
    "#     time = pd.to_datetime(time)\n",
    "    \n",
    "#     for j in range(len(var_names_summa)): # variable\n",
    "#         var_name_summa = var_names_summa[j]\n",
    "#         var_unit = var_units_summa[var_names_summa.index(var_name_summa)]\n",
    "        \n",
    "#         var_value = ds[var_name_summa].values[:] # (time, hru). or (time, spectral_bands, hru) for radiation\n",
    "       \n",
    "#         # sum up the visible and near-infra-red spectrums\n",
    "#         if var_name_summa in ['spectralIncomingDirect_mean', 'spectralIncomingDiffuse_mean']:\n",
    "#             if np.count_nonzero(var_value) == 0:\n",
    "#                 print('***** %s contains only zeros *****'%(var_name_summa))\n",
    "#             var_value = np.nansum(var_value,axis=1)\n",
    "            \n",
    "#         # convert unit\n",
    "#         if var_unit == 'kg m-2 s-1': # flux to mm/day\n",
    "#             var_value = var_value*86400 \n",
    "#         elif var_unit == 'kg m-2': # unit water storage to depth\n",
    "#             var_value = var_value\n",
    "#         elif var_unit == 'm s-1': # rate to mm/d\n",
    "#             var_value = var_value*1000*86400 \n",
    "#         elif var_unit == 'K': # temperature to C\n",
    "#             var_value = var_value - 273.15 \n",
    "#         elif var_unit == 'm': # to mm\n",
    "#             var_value = var_value*1000 \n",
    "        \n",
    "#         df = pd.DataFrame(var_value, index=time)\n",
    "    \n",
    "#         # calculate monthly mean \n",
    "#         df_avg = df.resample('M').mean()\n",
    "#         data_lev_dic[var_name_summa] = df_avg   \n",
    "\n",
    "#     # save to the big dic\n",
    "#     data_dic[label]=data_lev_dic\n",
    "    \n",
    "# # --- read GRU shapefile\n",
    "# gru_gpd = gpd.read_file(sub_shp_prj)\n",
    "# gru_gpd_prj = gru_gpd.to_crs(wgs_crs)\n",
    "\n",
    "# # --- read stream shapefile\n",
    "# stream_gpd = gpd.read_file(stream_clip)\n",
    "# stream_gpd_prj = stream_gpd.to_crs(wgs_crs)\n",
    "\n",
    "# # --- read HRU shapefile\n",
    "# hru_gpd_dic = {}\n",
    "# for i in range(level_num+1): # hru level\n",
    "#     label=label_basename+str(i) \n",
    "\n",
    "#     # read HRU shapefile \n",
    "#     hru_elmn_str = label+'_elmn'     \n",
    "#     hru_vector_elmn = os.path.join(case_dir, hru_elmn_str+'.shp')          \n",
    "#     hru_gpd = gpd.read_file(hru_vector_elmn)\n",
    "#     hru_gpd_prj = hru_gpd.to_crs(wgs_crs)\n",
    "#     hru_gpd_dic[label]=hru_gpd_prj\n",
    "\n",
    "# # ============== PART 2. Identify vmin and vmax ==============\n",
    "# print('vmin/vamx')\n",
    "# vmin_vmax_dic = {}\n",
    "# for i in range(level_num+1): # hru level\n",
    "#     label=label_basename+str(i) \n",
    "#     vmin_vmax_lev_dic = {}\n",
    "    \n",
    "#     for j in range(len(var_names_summa)): # variable\n",
    "#         var_name_summa = var_names_summa[j]\n",
    "\n",
    "#         # extract usefule variable value\n",
    "#         df = data_dic[label][var_name_summa]\n",
    "#         df_cut = df.truncate(before=plot_date_start_obj, after=plot_date_end_obj)\n",
    "#         data = df_cut.to_numpy()\n",
    "        \n",
    "#         vmin,vmax = np.nanmin(data),np.nanmax(data)\n",
    "#         vmin_vmax_lev_dic[var_name_summa] = [vmin,vmax]\n",
    "    \n",
    "#     # save to the big dic\n",
    "#     vmin_vmax_dic[label]=vmin_vmax_lev_dic    \n",
    "\n",
    "# ============== PART 3. Daily plot ==============\n",
    "print('plot')\n",
    "fontsize = 'medium'\n",
    "for level_i in range(level_num+1): # hru level\n",
    "    label=label_basename+str(level_i) \n",
    "    hru_gpd_prj = hru_gpd_dic[label]\n",
    "    output_subdir=os.path.join(output_dir,label)\n",
    "    \n",
    "    pool = mp.Pool(mp.cpu_count())    \n",
    "    for t_obj in tqdm(plot_date_range[0:1]):\n",
    "        t_obj_str = t_obj.strftime('%Y-%m')\n",
    "\n",
    "        nrow, ncol = 4,3 # variables\n",
    "        fig, ax = plt.subplots(nrow, ncol,figsize=[7.08*1.5*1.4, 7.08*1.2*1.5])#, constrained_layout=True)\n",
    "        fig.subplots_adjust(left=0.01, bottom=0.05, right=0.98, top=0.94, wspace=0.0, hspace=0.3)\n",
    "        fig.suptitle(label+' '+t_obj_str, fontsize='large',weight='semibold')\n",
    "\n",
    "        for i in range(nrow): \n",
    "            for j in range(ncol): \n",
    "\n",
    "                # identify variable and unit \n",
    "                k = i*ncol+j # variable index                \n",
    "                var_name_summa = var_names_summa[k]\n",
    "                var_name_plot = var_names_plot[k]\n",
    "                var_unit_plot = var_units_plot[k]  \n",
    "                \n",
    "                vmin,vmax = vmin_vmax_dic[label][var_name_summa]\n",
    "                if vmin==vmax and vmin==0:\n",
    "                    vmin,vmax = -10,10\n",
    "\n",
    "                # extract usefule variable value\n",
    "                df = data_dic[label][var_name_summa] # dataframe (time, hru)\n",
    "                df_cut = df.truncate(before=t_obj, after=t_obj)  \n",
    "                data = df_cut.to_numpy()\n",
    "                data = data.reshape((np.shape(data)[1],np.shape(data)[0]))            \n",
    "\n",
    "                # plot\n",
    "                # (1) plot gru\n",
    "                gru_gpd_prj.geometry.boundary.plot(color=None,edgecolor='k',linewidth=0.5,\n",
    "                                                   ax=ax[i,j],label='GRU') \n",
    "\n",
    "    #             # (2) plot stream\n",
    "    #             stream_gpd_prj.plot(color='b', linewidth=0.5, ax=ax[i,j], label='Stream')\n",
    "\n",
    "                # (3) plot data\n",
    "                # reference: https://geopandas.org/docs/user_guide/mapping.html\n",
    "                # reference: https://www.martinalarcon.org/2018-12-31-d-geopandas/\n",
    "                hru_gpd_prj[var_name_summa] = data\n",
    "                divider = make_axes_locatable(ax[i,j])\n",
    "                cax = divider.append_axes(\"right\", size=\"5%\", pad=-0.5)         \n",
    "                hru_gpd_prj.plot(column=var_name_summa, ax=ax[i,j], cmap='jet',\n",
    "                                 legend=True, cax=cax, vmin=vmin, vmax=vmax) #cmap='jet''Blues''terrain'\n",
    "\n",
    "                # Set the fontsize for each colorbar tick label\n",
    "                # manipulate the colorbar `cax`\n",
    "                cax.set_title(var_unit_plot, fontsize=fontsize)\n",
    "                for l in cax.yaxis.get_ticklabels():\n",
    "                    l.set_fontsize(fontsize)\n",
    "\n",
    "                # others\n",
    "                title = var_name_plot\n",
    "                ax[i,j].set_title(title,fontsize=fontsize,weight='semibold')\n",
    "                ax[i,j].tick_params(axis='both', direction='out', labelsize=fontsize)\n",
    "\n",
    "        ofile = t_obj.strftime('%Y%m')+'.png'\n",
    "        plt.savefig(os.path.join(output_subdir,ofile), dpi=80)\n",
    "        plt.close(fig)    \n",
    "    pool.close()   \n",
    "\n",
    "# ## Then convert daily plots to gif using command line.\n",
    "# ## convert -delay 10 plot_daily/*.png test.gif\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = data_dic['hru_lev0']['spectralIncomingDiffuse_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmin_vmax_dic[label]['spectralIncomingDiffuse_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
